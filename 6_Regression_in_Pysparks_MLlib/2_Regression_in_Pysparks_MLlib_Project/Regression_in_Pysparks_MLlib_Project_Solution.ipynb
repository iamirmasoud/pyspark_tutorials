{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression in PySpark's MLlib Project\n",
    "\n",
    "Now it's time to put what you've learned to into action with a REAL project! \n",
    "\n",
    "You have been hired as a consultant to a cement production company who wants to be able to improve their customer experience around a number of areas like being able to provide recommendations to cusomters on optimal amounts of certian ingredients in the cement making process and perhaps even create an application where users can input their own values and received a predicted cement strength!\n",
    "\n",
    "I have provided a list of question below to help guide you through this project but feel free to deviate and make this project your own! But first, a bit about this dataset.\n",
    "\n",
    "### About this dataset \n",
    "This dataset contains 1030 instances of concrete samples, containing 9 attributes (8 continuous and 1 discreate), and 1 continuous quantitative output variable. There are no missing attribute values.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "Given are the variable name, variable type, the measurement unit and a brief description. The concrete compressive strength is the outcome variable. The order of this listing corresponds to the order of numerals along the rows of the database.\n",
    "\n",
    "Name -- Data Type -- Measurement -- Description\n",
    "\n",
    "- Cement -- quantitative -- kg in a m3 mixture -- Input Variable \n",
    "- Blast Furnace Slag -- quantitative -- kg in a m3 mixture -- Input Variable \n",
    "- Fly Ash -- quantitative -- kg in a m3 mixture -- Input Variable \n",
    "- Water -- quantitative -- kg in a m3 mixture -- Input Variable \n",
    "- Superplasticizer -- quantitative -- kg in a m3 mixture -- Input Variable \n",
    "- Coarse Aggregate -- quantitative -- kg in a m3 mixture -- Input Variable \n",
    "- Fine Aggregate -- quantitative -- kg in a m3 mixture -- Input Variable \n",
    "- Age -- quantitative -- Day (1~365) -- Input Variable \n",
    "- Concrete compressive strength -- quantitative -- MPa -- Output Variable\n",
    "\n",
    "**Source:** https://www.kaggle.com/maajdl/yeh-concret-data\n",
    "\n",
    "**Dataset Name:** Concrete_Data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/12 11:46:13 WARN Utils: Your hostname, masoud-ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.7.139 instead (on interface wlp2s0)\n",
      "22/10/12 11:46:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/12 11:46:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.7.139:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Regression_Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9ba0045e90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's create our PySpark instance\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark  # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"Regression_Project\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's start by reading in our datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data prep\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import skewness, when, log, exp, col, min, array_min, array\n",
    "from pyspark.ml.feature import StringIndexer, MinMaxScaler\n",
    "\n",
    "# To check for multicolinearity\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "# For training and evaluation\n",
    "from pyspark.ml.regression import (\n",
    "    LinearRegression,\n",
    "    DecisionTreeRegressor,\n",
    "    GBTRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Datasets/\"\n",
    "df = spark.read.csv(path + \"Concrete_Data.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarseaggregate</th>\n",
       "      <th>fineaggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>csMPa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  flyash  water  superplasticizer  coarseaggregate  \\\n",
       "0   540.0    0.0     0.0  162.0               2.5           1040.0   \n",
       "1   540.0    0.0     0.0  162.0               2.5           1055.0   \n",
       "2   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "3   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "4   198.6  132.4     0.0  192.0               0.0            978.4   \n",
       "5   266.0  114.0     0.0  228.0               0.0            932.0   \n",
       "\n",
       "   fineaggregate  age  csMPa  \n",
       "0          676.0   28  79.99  \n",
       "1          676.0   28  61.89  \n",
       "2          594.0  270  40.27  \n",
       "3          594.0  365  41.05  \n",
       "4          825.5  360  44.30  \n",
       "5          670.0   90  47.03  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And of course the schema :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cement: double (nullable = true)\n",
      " |-- slag: double (nullable = true)\n",
      " |-- flyash: double (nullable = true)\n",
      " |-- water: double (nullable = true)\n",
      " |-- superplasticizer: double (nullable = true)\n",
      " |-- coarseaggregate: double (nullable = true)\n",
      " |-- fineaggregate: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- csMPa: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doulbe check to see if there are any missing values**\n",
    "\n",
    "Let's go ahead and drop any missing values for the sake of simplicity for this lecture as we have already covered the alternatives in subsequent lectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dropping missings: 1030\n",
      "after dropping missings 1030\n"
     ]
    }
   ],
   "source": [
    "# drop missing data\n",
    "drop = df.na.drop()\n",
    "print(\"before dropping missings:\", df.count())\n",
    "print(\"after dropping missings\", drop.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Which features are the strongest predictors of cement strength?\n",
    "\n",
    "Build your own ML model to figure this one out! This would be good information to give to our client so the sales reps can focus their efforts on certain ingredients to provide recommendations on. For example, if our clients had a customer that was struggling with their cement breaking, we could trouble shoot with them by starting with the factors that we know are important.\n",
    "\n",
    "So in order to do this, we first need to format our data and create a model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data \n",
    "\n",
    "Remember that MLlib requires all input columns of your dataframe to be vectorized. Good thing we created an awesome function to do that in the lectures, so we can simply copy and pasted that here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLRegressDFPrep(\n",
    "    df, input_columns, dependent_var, treat_outliers=True, treat_neg_values=True\n",
    "):\n",
    "\n",
    "    renamed = df.withColumnRenamed(dependent_var, \"label\")\n",
    "\n",
    "    # Make sure dependent variable is numeric and change if it's not\n",
    "    if renamed.schema[\"label\"].dataType != IntegerType():\n",
    "        renamed = renamed.withColumn(\"label\", renamed[\"label\"].cast(FloatType()))\n",
    "\n",
    "    # Convert all string type data in the input column list to numeric\n",
    "    # Otherwise the Algorithm will not be able to process it\n",
    "    numeric_inputs = []\n",
    "    string_inputs = []\n",
    "    for column in input_columns:\n",
    "        if renamed.schema[column].dataType == StringType():\n",
    "            new_col_name = column + \"_num\"\n",
    "            string_inputs.append(new_col_name)\n",
    "        else:\n",
    "            numeric_inputs.append(column)\n",
    "            indexed = renamed\n",
    "\n",
    "    if len(string_inputs) != 0:  # If the datafraem contains string types\n",
    "        for column in input_columns:\n",
    "            if renamed.schema[column].dataType == StringType():\n",
    "                indexer = StringIndexer(inputCol=column, outputCol=column + \"_num\")\n",
    "                indexed = indexer.fit(renamed).transform(renamed)\n",
    "    else:\n",
    "        indexed = renamed\n",
    "\n",
    "    if treat_outliers == True:\n",
    "        print(\"Correcting for non normality now!\")\n",
    "        # empty dictionary d\n",
    "        d = {}\n",
    "        # Create a dictionary of quantiles\n",
    "        for col in numeric_inputs:\n",
    "            d[col] = indexed.approxQuantile(\n",
    "                col, [0.01, 0.99], 0.25\n",
    "            )  # if you want to make it go faster increase the last number\n",
    "        # Now fill in the values\n",
    "        for col in numeric_inputs:\n",
    "            skew = indexed.agg(skewness(indexed[col])).collect()  # check for skewness\n",
    "            skew = skew[0][0]\n",
    "            # This function will floor, cap and then log+1 (just in case there are 0 values)\n",
    "            if skew > 1:\n",
    "                indexed = indexed.withColumn(\n",
    "                    col,\n",
    "                    log(\n",
    "                        when(df[col] < d[col][0], d[col][0])\n",
    "                        .when(indexed[col] > d[col][1], d[col][1])\n",
    "                        .otherwise(indexed[col])\n",
    "                        + 1\n",
    "                    ).alias(col),\n",
    "                )\n",
    "                print(\n",
    "                    col + \" has been treated for positive (right) skewness. (skew =)\",\n",
    "                    skew,\n",
    "                    \")\",\n",
    "                )\n",
    "            elif skew < -1:\n",
    "                indexed = indexed.withColumn(\n",
    "                    col,\n",
    "                    exp(\n",
    "                        when(df[col] < d[col][0], d[col][0])\n",
    "                        .when(indexed[col] > d[col][1], d[col][1])\n",
    "                        .otherwise(indexed[col])\n",
    "                    ).alias(col),\n",
    "                )\n",
    "                print(\n",
    "                    col + \" has been treated for negative (left) skewness. (skew =\",\n",
    "                    skew,\n",
    "                    \")\",\n",
    "                )\n",
    "\n",
    "    # Produce a warning if there are negative values in the dataframe that Naive Bayes cannot be used.\n",
    "    # Note: we only need to check the numeric input values since anything that is indexed won't have negative values\n",
    "    minimums = df.select(\n",
    "        [min(c).alias(c) for c in df.columns if c in numeric_inputs]\n",
    "    )  # Calculate the mins for all columns in the df\n",
    "    min_array = minimums.select(\n",
    "        array(numeric_inputs).alias(\"mins\")\n",
    "    )  # Create an array for all mins and select only the input cols\n",
    "    df_minimum = min_array.select(\n",
    "        array_min(min_array.mins)\n",
    "    ).collect()  # Collect golobal min as Python object\n",
    "    df_minimum = df_minimum[0][0]  # Slice to get the number itself\n",
    "\n",
    "    features_list = numeric_inputs + string_inputs\n",
    "    assembler = VectorAssembler(inputCols=features_list, outputCol=\"features\")\n",
    "    output = assembler.transform(indexed).select(\"features\", \"label\")\n",
    "\n",
    "    #     final_data = output.select('features','label') #drop everything else\n",
    "\n",
    "    # Now check for negative values and ask user if they want to correct that?\n",
    "    if df_minimum < 0:\n",
    "        print(\" \")\n",
    "        print(\n",
    "            \"WARNING: The Naive Bayes Regressor will not be able to process your dataframe as it contains negative values\"\n",
    "        )\n",
    "        print(\" \")\n",
    "\n",
    "    if treat_neg_values == True:\n",
    "        print(\n",
    "            \"You have opted to correct that by rescaling all your features to a range of 0 to 1\"\n",
    "        )\n",
    "        print(\" \")\n",
    "        print(\"Rescaling the dataframe....\")\n",
    "        scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "        # Compute summary statistics and generate MinMaxScalerModel\n",
    "        global scalerModel\n",
    "        scalerModel = scaler.fit(output)\n",
    "\n",
    "        # rescale each feature to range [min, max].\n",
    "        scaled_data = scalerModel.transform(output)\n",
    "        final_data = scaled_data.select(\"label\", \"scaledFeatures\")\n",
    "        final_data = final_data.withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "        print(\"Done!\")\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            \"You have opted not to correct that therefore you will not be able to use to Naive Bayes Regressor\"\n",
    "        )\n",
    "        print(\"We will return the dataframe unscaled.\")\n",
    "        final_data = output\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcting for non normality now!\n",
      "age has been treated for positive (right) skewness. (skew =) 3.2644145354168086 )\n",
      "You have opted to correct that by rescaling all your features to a range of 0 to 1\n",
      " \n",
      "Rescaling the dataframe....\n",
      "Done!\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|79.99|[1.0,0.0,0.0,0.32...|\n",
      "|61.89|[1.0,0.0,0.0,0.32...|\n",
      "|40.27|[0.52625570776255...|\n",
      "|41.05|[0.52625570776255...|\n",
      "| 44.3|[0.22054794520547...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_columns = df.columns[:-1]  # all except the last one\n",
    "dependent_var = df.columns[-1]  # The last column\n",
    "\n",
    "final_data = MLRegressDFPrep(df, input_columns, dependent_var)\n",
    "final_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Multicollinearity\n",
    "\n",
    "Let's make sure we don't have any multicollinearity before we go any further. Remeber the following guidelines for pearson's:\n",
    "\n",
    "- .00-.19 (very weak)\n",
    "- .20-.39 (weak)\n",
    "- .40-.59 (moderate)\n",
    "- .60-.79 (strong)\n",
    "- .80-1.0 (very strong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "pearsonCorr = Correlation.corr(final_data, \"features\", \"pearson\").collect()[0][0]\n",
    "corr_array = pearsonCorr.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pd = pd.DataFrame(corr_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ea861_row0_col0, #T_ea861_row1_col1, #T_ea861_row2_col2, #T_ea861_row3_col3, #T_ea861_row4_col4, #T_ea861_row5_col5, #T_ea861_row6_col6, #T_ea861_row7_col7 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea861_row0_col1 {\n",
       "  background-color: #f0f6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row0_col2, #T_ea861_row1_col5, #T_ea861_row2_col0, #T_ea861_row2_col1, #T_ea861_row3_col4, #T_ea861_row3_col6, #T_ea861_row4_col3, #T_ea861_row6_col7 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row0_col3 {\n",
       "  background-color: #a8cee4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row0_col4 {\n",
       "  background-color: #7fb9da;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row0_col5 {\n",
       "  background-color: #dceaf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row0_col6 {\n",
       "  background-color: #d8e7f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row0_col7 {\n",
       "  background-color: #e2edf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row1_col0 {\n",
       "  background-color: #e6f0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row1_col2 {\n",
       "  background-color: #edf4fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row1_col3, #T_ea861_row4_col6 {\n",
       "  background-color: #7ab6d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row1_col4 {\n",
       "  background-color: #8abfdd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row1_col6 {\n",
       "  background-color: #e0ecf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row1_col7, #T_ea861_row2_col7, #T_ea861_row6_col5 {\n",
       "  background-color: #e7f0fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row2_col3 {\n",
       "  background-color: #c8dcf0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row2_col4 {\n",
       "  background-color: #4292c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea861_row2_col5 {\n",
       "  background-color: #cde0f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row2_col6 {\n",
       "  background-color: #a1cbe2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row3_col0 {\n",
       "  background-color: #cbdef1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row3_col1 {\n",
       "  background-color: #aed1e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row3_col2 {\n",
       "  background-color: #e3eef9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row3_col5 {\n",
       "  background-color: #e7f1fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row3_col7 {\n",
       "  background-color: #c4daee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row4_col0 {\n",
       "  background-color: #a6cee4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row4_col1, #T_ea861_row5_col2 {\n",
       "  background-color: #bed8ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row4_col2 {\n",
       "  background-color: #5aa2cf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea861_row4_col5 {\n",
       "  background-color: #f5f9fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row4_col7 {\n",
       "  background-color: #ebf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row5_col0 {\n",
       "  background-color: #cfe1f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row5_col1 {\n",
       "  background-color: #f2f7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row5_col3, #T_ea861_row7_col0 {\n",
       "  background-color: #bad6eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row5_col4 {\n",
       "  background-color: #c9ddf0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row5_col6 {\n",
       "  background-color: #d2e3f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row5_col7 {\n",
       "  background-color: #eaf2fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row6_col0 {\n",
       "  background-color: #deebf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row6_col1 {\n",
       "  background-color: #f1f7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row6_col2 {\n",
       "  background-color: #a9cfe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row6_col3 {\n",
       "  background-color: #dfebf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row6_col4 {\n",
       "  background-color: #61a7d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea861_row7_col1 {\n",
       "  background-color: #cadef0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row7_col2 {\n",
       "  background-color: #bfd8ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row7_col3 {\n",
       "  background-color: #6caed6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ea861_row7_col4 {\n",
       "  background-color: #a0cbe2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row7_col5 {\n",
       "  background-color: #d1e2f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ea861_row7_col6 {\n",
       "  background-color: #caddf0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ea861_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >0</th>\n",
       "      <th class=\"col_heading level0 col1\" >1</th>\n",
       "      <th class=\"col_heading level0 col2\" >2</th>\n",
       "      <th class=\"col_heading level0 col3\" >3</th>\n",
       "      <th class=\"col_heading level0 col4\" >4</th>\n",
       "      <th class=\"col_heading level0 col5\" >5</th>\n",
       "      <th class=\"col_heading level0 col6\" >6</th>\n",
       "      <th class=\"col_heading level0 col7\" >7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ea861_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ea861_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_ea861_row0_col1\" class=\"data row0 col1\" >-0.275216</td>\n",
       "      <td id=\"T_ea861_row0_col2\" class=\"data row0 col2\" >-0.397467</td>\n",
       "      <td id=\"T_ea861_row0_col3\" class=\"data row0 col3\" >-0.081587</td>\n",
       "      <td id=\"T_ea861_row0_col4\" class=\"data row0 col4\" >0.092386</td>\n",
       "      <td id=\"T_ea861_row0_col5\" class=\"data row0 col5\" >-0.109349</td>\n",
       "      <td id=\"T_ea861_row0_col6\" class=\"data row0 col6\" >-0.222718</td>\n",
       "      <td id=\"T_ea861_row0_col7\" class=\"data row0 col7\" >0.003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea861_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ea861_row1_col0\" class=\"data row1 col0\" >-0.275216</td>\n",
       "      <td id=\"T_ea861_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_ea861_row1_col2\" class=\"data row1 col2\" >-0.323580</td>\n",
       "      <td id=\"T_ea861_row1_col3\" class=\"data row1 col3\" >0.107252</td>\n",
       "      <td id=\"T_ea861_row1_col4\" class=\"data row1 col4\" >0.043270</td>\n",
       "      <td id=\"T_ea861_row1_col5\" class=\"data row1 col5\" >-0.283999</td>\n",
       "      <td id=\"T_ea861_row1_col6\" class=\"data row1 col6\" >-0.281603</td>\n",
       "      <td id=\"T_ea861_row1_col7\" class=\"data row1 col7\" >-0.020881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea861_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ea861_row2_col0\" class=\"data row2 col0\" >-0.397467</td>\n",
       "      <td id=\"T_ea861_row2_col1\" class=\"data row2 col1\" >-0.323580</td>\n",
       "      <td id=\"T_ea861_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_ea861_row2_col3\" class=\"data row2 col3\" >-0.256984</td>\n",
       "      <td id=\"T_ea861_row2_col4\" class=\"data row2 col4\" >0.377503</td>\n",
       "      <td id=\"T_ea861_row2_col5\" class=\"data row2 col5\" >-0.009961</td>\n",
       "      <td id=\"T_ea861_row2_col6\" class=\"data row2 col6\" >0.079108</td>\n",
       "      <td id=\"T_ea861_row2_col7\" class=\"data row2 col7\" >-0.019745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea861_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ea861_row3_col0\" class=\"data row3 col0\" >-0.081587</td>\n",
       "      <td id=\"T_ea861_row3_col1\" class=\"data row3 col1\" >0.107252</td>\n",
       "      <td id=\"T_ea861_row3_col2\" class=\"data row3 col2\" >-0.256984</td>\n",
       "      <td id=\"T_ea861_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_ea861_row3_col4\" class=\"data row3 col4\" >-0.657533</td>\n",
       "      <td id=\"T_ea861_row3_col5\" class=\"data row3 col5\" >-0.182294</td>\n",
       "      <td id=\"T_ea861_row3_col6\" class=\"data row3 col6\" >-0.450661</td>\n",
       "      <td id=\"T_ea861_row3_col7\" class=\"data row3 col7\" >0.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea861_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ea861_row4_col0\" class=\"data row4 col0\" >0.092386</td>\n",
       "      <td id=\"T_ea861_row4_col1\" class=\"data row4 col1\" >0.043270</td>\n",
       "      <td id=\"T_ea861_row4_col2\" class=\"data row4 col2\" >0.377503</td>\n",
       "      <td id=\"T_ea861_row4_col3\" class=\"data row4 col3\" >-0.657533</td>\n",
       "      <td id=\"T_ea861_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_ea861_row4_col5\" class=\"data row4 col5\" >-0.265999</td>\n",
       "      <td id=\"T_ea861_row4_col6\" class=\"data row4 col6\" >0.222691</td>\n",
       "      <td id=\"T_ea861_row4_col7\" class=\"data row4 col7\" >-0.048453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea861_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ea861_row5_col0\" class=\"data row5 col0\" >-0.109349</td>\n",
       "      <td id=\"T_ea861_row5_col1\" class=\"data row5 col1\" >-0.283999</td>\n",
       "      <td id=\"T_ea861_row5_col2\" class=\"data row5 col2\" >-0.009961</td>\n",
       "      <td id=\"T_ea861_row5_col3\" class=\"data row5 col3\" >-0.182294</td>\n",
       "      <td id=\"T_ea861_row5_col4\" class=\"data row5 col4\" >-0.265999</td>\n",
       "      <td id=\"T_ea861_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_ea861_row5_col6\" class=\"data row5 col6\" >-0.178481</td>\n",
       "      <td id=\"T_ea861_row5_col7\" class=\"data row5 col7\" >-0.038134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea861_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ea861_row6_col0\" class=\"data row6 col0\" >-0.222718</td>\n",
       "      <td id=\"T_ea861_row6_col1\" class=\"data row6 col1\" >-0.281603</td>\n",
       "      <td id=\"T_ea861_row6_col2\" class=\"data row6 col2\" >0.079108</td>\n",
       "      <td id=\"T_ea861_row6_col3\" class=\"data row6 col3\" >-0.450661</td>\n",
       "      <td id=\"T_ea861_row6_col4\" class=\"data row6 col4\" >0.222691</td>\n",
       "      <td id=\"T_ea861_row6_col5\" class=\"data row6 col5\" >-0.178481</td>\n",
       "      <td id=\"T_ea861_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_ea861_row6_col7\" class=\"data row6 col7\" >-0.114853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ea861_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ea861_row7_col0\" class=\"data row7 col0\" >0.003339</td>\n",
       "      <td id=\"T_ea861_row7_col1\" class=\"data row7 col1\" >-0.020881</td>\n",
       "      <td id=\"T_ea861_row7_col2\" class=\"data row7 col2\" >-0.019745</td>\n",
       "      <td id=\"T_ea861_row7_col3\" class=\"data row7 col3\" >0.170213</td>\n",
       "      <td id=\"T_ea861_row7_col4\" class=\"data row7 col4\" >-0.048453</td>\n",
       "      <td id=\"T_ea861_row7_col5\" class=\"data row7 col5\" >-0.038134</td>\n",
       "      <td id=\"T_ea861_row7_col6\" class=\"data row7 col6\" >-0.114853</td>\n",
       "      <td id=\"T_ea861_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9b59fb0bd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_pd.style.background_gradient(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the third and fourth features are strongly correlated, but the rest are okay. We may want to consider removing one of the variables in each correlation pair if we decide to use a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataframe into training and evaluation (test)\n",
    "\n",
    "I'm going with 70/30 but you can use your own mix if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test our package of algorithms to see which one works best!\n",
    "\n",
    "Next, we need to create our model. Let's use our handy dandy function that iterativley runs through all Regression algorithms. I just copy and pasted this from the previous lecture! How easy is that?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RegressTrainEval(regressor):\n",
    "    def FindMtype(regressor):\n",
    "        # Intstantiate Model\n",
    "        M = regressor\n",
    "        # Learn what it is\n",
    "        Mtype = type(M).__name__\n",
    "\n",
    "        return Mtype\n",
    "\n",
    "    Mtype = FindMtype(regressor)\n",
    "    #     print('\\033[1m' + Mtype + ':' + '\\033[0m')\n",
    "\n",
    "    if Mtype == \"LinearRegression\":\n",
    "\n",
    "        # first without cross val\n",
    "        fitModel = regressor.fit(train)\n",
    "\n",
    "        # Load the Summary\n",
    "        trainingSummary = fitModel.summary\n",
    "\n",
    "        # Print the coefficients and intercept for linear regression\n",
    "        print(\n",
    "            \"\\033[1m\"\n",
    "            + \"Linear Regression Model Summary without cross validation:\"\n",
    "            + \"\\033[0m\"\n",
    "        )\n",
    "        print(\" \")\n",
    "        print(\"Coefficients: %s\" % str(fitModel.coefficients))\n",
    "        print(\"Intercept: %s\" % str(fitModel.intercept))\n",
    "        print(\"\")\n",
    "\n",
    "        # Summarize the model over the training set and print out some metrics\n",
    "        print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "        print(\n",
    "            \"objectiveHistory: (scaled loss + regularization) at each iteration \\n %s\"\n",
    "            % str(trainingSummary.objectiveHistory)\n",
    "        )\n",
    "        print(\"\")\n",
    "\n",
    "        # Print the Errors\n",
    "        print(\"Training RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "        print(\"Training r2: %f\" % trainingSummary.r2)\n",
    "        print(\"\")\n",
    "\n",
    "        # Now load the test results\n",
    "        test_results = fitModel.evaluate(test)\n",
    "\n",
    "        # And print them\n",
    "        print(\"Test RMSE: {}\".format(test_results.rootMeanSquaredError))\n",
    "        print(\"Test r2: {}\".format(test_results.r2))\n",
    "        print(\"\")\n",
    "\n",
    "        # Now train with cross val\n",
    "        paramGrid = (\n",
    "            ParamGridBuilder()  #              .addGrid(regressor.maxIter, [10, 15]) \\\n",
    "            .addGrid(regressor.regParam, [0.1, 0.01])\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "        # Evaluator\n",
    "        revaluator = RegressionEvaluator(metricName=\"rmse\")\n",
    "\n",
    "        # Cross Validator requires all of the following parameters:\n",
    "        crossval = CrossValidator(\n",
    "            estimator=regressor,\n",
    "            estimatorParamMaps=paramGrid,\n",
    "            evaluator=revaluator,\n",
    "            numFolds=2,\n",
    "        )  # 3 is best practice\n",
    "\n",
    "        print(\n",
    "            \"\\033[1m\"\n",
    "            + \"Linear Regression Model Summary WITH cross validation:\"\n",
    "            + \"\\033[0m\"\n",
    "        )\n",
    "        print(\" \")\n",
    "        # Run cross validations\n",
    "        fitModel = crossval.fit(train)\n",
    "\n",
    "        # Get Model Summary Statistics\n",
    "        ModelSummary = fitModel.bestModel.summary\n",
    "        print(\n",
    "            \"Coefficient Standard Errors: \"\n",
    "            + str(ModelSummary.coefficientStandardErrors)\n",
    "        )\n",
    "        print(\" \")\n",
    "        print(\"P Values: \" + str(ModelSummary.pValues))  # Last element is the intercept\n",
    "        print(\" \")\n",
    "\n",
    "        global LR_Pvalues\n",
    "        LR_Pvalues = ModelSummary.pValues\n",
    "\n",
    "        # save model\n",
    "        global LR_BestModel\n",
    "        LR_BestModel = fitModel.bestModel\n",
    "\n",
    "        # Use test set here so we can measure the accuracy of our model on new data\n",
    "        ModelPredictions = fitModel.transform(test)\n",
    "\n",
    "        # cvModel uses the best model found from the Cross Validation\n",
    "        # Evaluate best model\n",
    "        test_results = revaluator.evaluate(ModelPredictions)\n",
    "        print(\"RMSE:\", test_results)\n",
    "\n",
    "        # Set the column names to match the external results dataframe that we will join with later:\n",
    "        columns = [\"Regressor\", \"Result\"]\n",
    "\n",
    "        # Format results and return\n",
    "        rmse_str = [str(test_results)]  # make this a string and convert to a list\n",
    "        Mtype = [Mtype]  # make this a string\n",
    "        result = spark.createDataFrame(zip(Mtype, rmse_str), schema=columns)\n",
    "        result = result.withColumn(\"Result\", result.Result.substr(0, 5))\n",
    "        return result\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Add parameters of your choice here:\n",
    "        if Mtype in (\"RandomForestRegressor\"):\n",
    "            paramGrid = (\n",
    "                ParamGridBuilder()  #                            .addGrid(regressor.maxDepth, [2, 5, 10])\n",
    "                #                            .addGrid(regressor.maxBins, [5, 10, 20])\n",
    "                .addGrid(regressor.numTrees, [5, 20]).build()\n",
    "            )\n",
    "\n",
    "        # Add parameters of your choice here:\n",
    "        if Mtype in (\"GBTRegressor\"):\n",
    "            paramGrid = (\n",
    "                ParamGridBuilder()  #                          .addGrid(regressor.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "                .addGrid(regressor.maxBins, [10, 20])\n",
    "                .addGrid(regressor.maxIter, [10, 15])\n",
    "                .build()\n",
    "            )\n",
    "\n",
    "        # Add parameters of your choice here:\n",
    "        if Mtype in (\"DecisionTreeRegressor\"):\n",
    "            paramGrid = (\n",
    "                ParamGridBuilder()  #                          .addGrid(regressor.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "                .addGrid(regressor.maxBins, [10, 20, 40])\n",
    "                .build()\n",
    "            )\n",
    "\n",
    "        # Cross Validator requires all of the following parameters:\n",
    "        crossval = CrossValidator(\n",
    "            estimator=regressor,\n",
    "            estimatorParamMaps=paramGrid,\n",
    "            evaluator=RegressionEvaluator(metricName=\"rmse\"),\n",
    "            numFolds=2,\n",
    "        )  # 3 is best practice\n",
    "        # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "        fitModel = crossval.fit(train)\n",
    "\n",
    "        # Get Best Model\n",
    "        BestModel = fitModel.bestModel\n",
    "\n",
    "        # FEATURE IMPORTANCES\n",
    "        # Estimate of the importance of each feature.\n",
    "        # Each featureâ€™s importance is the average of its importance across all trees\n",
    "        # in the ensemble The importance vector is normalized to sum to 1.\n",
    "        print(\" \")\n",
    "        print(\"\\033[1m\" + Mtype, \" Feature Importances\" + \"\\033[0m\")\n",
    "        print(\"(Scores add up to 1)\")\n",
    "        print(\"Lowest score is the least important\")\n",
    "        print(\" \")\n",
    "        print(BestModel.featureImportances)\n",
    "\n",
    "        # Create Global Variables for feature importances and models\n",
    "        if Mtype in (\"DecisionTreeRegressor\"):\n",
    "            global DT_featureimportances\n",
    "            DT_featureimportances = BestModel.featureImportances.toArray()\n",
    "            global DT_BestModel\n",
    "            DT_BestModel = fitModel.bestModel\n",
    "        if Mtype in (\"GBTRegressor\"):\n",
    "            global GBT_featureimportances\n",
    "            GBT_featureimportances = BestModel.featureImportances.toArray()\n",
    "            global GBT_BestModel\n",
    "            GBT_BestModel = fitModel.bestModel\n",
    "        if Mtype in (\"RandomForestRegressor\"):\n",
    "            global RF_featureimportances\n",
    "            RF_featureimportances = BestModel.featureImportances.toArray()\n",
    "            global RF_BestModel\n",
    "            RF_BestModel = fitModel.bestModel\n",
    "\n",
    "        # Set the column names to match the external results dataframe that we will join with later:\n",
    "        columns = [\"Regressor\", \"Result\"]\n",
    "\n",
    "        # Make predictions.\n",
    "        predictions = fitModel.transform(test)\n",
    "        # Select (prediction, true label) and compute test error\n",
    "        evaluator = RegressionEvaluator(metricName=\"rmse\")\n",
    "        rmse = evaluator.evaluate(predictions)\n",
    "        rmse_str = [str(rmse)]  # make this a string and convert to a list\n",
    "        Mtype = [Mtype]  # make this a string\n",
    "        result = spark.createDataFrame(zip(Mtype, rmse_str), schema=columns)\n",
    "        result = result.withColumn(\"Result\", result.Result.substr(0, 5))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And now run it!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/12 12:19:47 WARN Instrumentation: [387deb1d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "\u001b[1mLinear Regression Model Summary without cross validation:\u001b[0m\n",
      " \n",
      "Coefficients: [55.48572873374682,38.86089265312072,15.982317004302573,-20.939887735795974,4.164352117078743,8.138959409328491,9.813919386968742,49.85602701604337]\n",
      "Intercept: -22.684230043792546\n",
      "\n",
      "numIterations: 0\n",
      "objectiveHistory: (scaled loss + regularization) at each iteration \n",
      " [0.0]\n",
      "\n",
      "Training RMSE: 7.225520\n",
      "Training r2: 0.818157\n",
      "\n",
      "Test RMSE: 7.116492024917569\n",
      "Test r2: 0.8044775405465747\n",
      "\n",
      "\u001b[1mLinear Regression Model Summary WITH cross validation:\u001b[0m\n",
      " \n",
      "Coefficient Standard Errors: [3.0352634766340616, 2.947618385654055, 2.0368867542367637, 4.160210350124244, 2.530915729541024, 2.662137713791819, 3.4920960055544343, 1.3435586335081906, 6.832233643137161]\n",
      " \n",
      "P Values: [0.0, 0.0, 4.4853010194856324e-14, 3.6737911313089455e-07, 0.09873291921322425, 0.003442065398903127, 0.007641619622388518, 0.0, 0.0015344389842135708]\n",
      " \n",
      "RMSE: 7.120777238470379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/masoud/anaconda3/envs/spark_env/lib/python3.7/site-packages/pyspark/jars/spark-core_2.12-3.3.0.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\u001b[1mRandomForestRegressor  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(8,[0,1,2,3,4,5,6,7],[0.25339531333219856,0.06292547351470439,0.04470348429472512,0.1543825075053736,0.04385531119266879,0.03103548573293389,0.043653242796174906,0.3660491816312207])\n",
      " \n",
      "\u001b[1mGBTRegressor  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(8,[0,1,2,3,4,5,6,7],[0.19952097685252684,0.08473002284138066,0.0453332054159769,0.16350825052828175,0.10430505260875644,0.06339642717352316,0.09875088439402281,0.24045518018553136])\n",
      " \n",
      "\u001b[1mDecisionTreeRegressor  Feature Importances\u001b[0m\n",
      "(Scores add up to 1)\n",
      "Lowest score is the least important\n",
      " \n",
      "(8,[0,1,2,3,4,5,7],[0.3425157306189419,0.10891819540859343,0.011852898744709251,0.1024530244612682,0.0783901503609711,0.004575600179783972,0.35129440022573216])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1519:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------+\n",
      "|Regressor            |Result|\n",
      "+---------------------+------+\n",
      "|LinearRegression     |7.120 |\n",
      "|RandomForestRegressor|7.038 |\n",
      "|GBTRegressor         |6.572 |\n",
      "|DecisionTreeRegressor|8.298 |\n",
      "+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressors = [\n",
    "    LinearRegression(),\n",
    "    RandomForestRegressor(),\n",
    "    GBTRegressor(),\n",
    "    DecisionTreeRegressor(),\n",
    "]\n",
    "\n",
    "# set up your results table\n",
    "columns = [\"Regressor\", \"Result\"]\n",
    "vals = [(\"Place Holder\", \"N/A\")]\n",
    "results = spark.createDataFrame(vals, columns)\n",
    "\n",
    "for regressor in regressors:\n",
    "    new_result = RegressTrainEval(regressor)\n",
    "    results = results.union(new_result)\n",
    "results = results.where(\"Regressor!='Place Holder'\")\n",
    "results.show(100, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now for the results!**\n",
    "\n",
    "Now it's time to query the feature importance lists/arrays that were created above! We can use this information to fine tune our model if we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest best features:  [7 0 3 1]\n",
      "GBT best features:  [7 0 3 4]\n",
      "Decision Tree best features:  [7 0 1 3]\n",
      "Linear Regression best features:  [0.0, 0.0, 4.4853010194856324e-14, 3.6737911313089455e-07, 0.09873291921322425, 0.003442065398903127, 0.007641619622388518, 0.0, 0.0015344389842135708]\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "\n",
    "print(\"Random Forest best features: \", RF_featureimportances.argsort()[-n:][::-1])\n",
    "print(\"GBT best features: \", GBT_featureimportances.argsort()[-n:][::-1])\n",
    "print(\"Decision Tree best features: \", DT_featureimportances.argsort()[-n:][::-1])\n",
    "print(\"Linear Regression best features: \", LR_Pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. For the following given inputs, what would be the estimated cement strength?\n",
    "\n",
    "- Cement: 540\n",
    "- Blast Furnace Slag: 0\n",
    "- Fly Ash: 0\n",
    "- Water: 162\n",
    "- Superplasticizer: 2.5\n",
    "- Coarse Aggregate: 1040\n",
    "- Fine Aggregate: 676\n",
    "- Age: 28\n",
    "\n",
    "The correct answer according to my model is 79.99. Let's see what you get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+-----+----------------+---------------+-------------+-----------------+\n",
      "|cement|slag|flyash|water|superplasticizer|coarseaggregate|fineaggregate|              age|\n",
      "+------+----+------+-----+----------------+---------------+-------------+-----------------+\n",
      "|   540| 0.0|   0.0|  162|             2.5|           1040|          676|4.332204510175204|\n",
      "+------+----+------+-----+----------------+---------------+-------------+-----------------+\n",
      "\n",
      "+--------------------+----------------+\n",
      "|            features|      prediction|\n",
      "+--------------------+----------------+\n",
      "|[1.0,0.0,0.0,0.32...|68.9038707065148|\n",
      "+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manually input our values from above.\n",
    "values = [(540, 0.0, 0.0, 162, 2.5, 1040, 676, 28)]\n",
    "# Fetch the column names\n",
    "column_names = df.columns\n",
    "column_names = column_names[0:8]\n",
    "# Map values to column names (always better to soft code :) )\n",
    "# test = spark.createDataFrame(values,[\"cement\",\"slag\",\"flyash\",\"water\",\"superplasticizer\",\"coarseaggregate\",\"fineaggregate\",\"age\"])\n",
    "test = spark.createDataFrame(values, column_names)\n",
    "\n",
    "# remember that we treated age for right skewness\n",
    "# so we need to convert the raw value to the transformed value\n",
    "test = test.withColumn(\"age\", log(\"age\") + 1)\n",
    "test.show()\n",
    "# Transform for a vector\n",
    "features_list = [\n",
    "    \"cement\",\n",
    "    \"slag\",\n",
    "    \"flyash\",\n",
    "    \"water\",\n",
    "    \"superplasticizer\",\n",
    "    \"coarseaggregate\",\n",
    "    \"fineaggregate\",\n",
    "    \"age\",\n",
    "]\n",
    "assembler = VectorAssembler(inputCols=features_list, outputCol=\"features\")\n",
    "test = assembler.transform(test).select(\"features\")\n",
    "\n",
    "# rescale each feature to range [min, max].\n",
    "scaled_test = scalerModel.transform(test)\n",
    "final_test = scaled_test.select(\"scaledFeatures\")\n",
    "final_test = final_test.withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "\n",
    "predictions = LR_BestModel.transform(final_test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interact with a user!\n",
    "\n",
    "Now see if you can ask users to input their own value for Age (keeping all other values the same from the question above) and return a predicted value for the cement stength. \n",
    "\n",
    "We did not cover this is in the lecture so you'll have to put your thinking cap on. Accepting user input in PySpark works just like it does in traditional Python.\n",
    "<br>\n",
    "\n",
    "val = input(\"Enter your value: \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How old is your cement? 10\n",
      "Your predicted cement stregth is:  59.06154790468964\n"
     ]
    }
   ],
   "source": [
    "age_val = input(\"How old is your cement? \")\n",
    "values = [(540, 0.0, 0.0, 162, 2.5, 1040, 676, age_val)]\n",
    "test = spark.createDataFrame(\n",
    "    values,\n",
    "    [\n",
    "        \"cement\",\n",
    "        \"slag\",\n",
    "        \"flyash\",\n",
    "        \"water\",\n",
    "        \"superplasticizer\",\n",
    "        \"coarseaggregate\",\n",
    "        \"fineaggregate\",\n",
    "        \"age\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# remember that we treated age for right skewness\n",
    "# so we need to convert the raw value to the transformed value\n",
    "test = test.withColumn(\"age\", log(\"age\") + 1)\n",
    "\n",
    "# Transform for a vector\n",
    "features_list = [\n",
    "    \"cement\",\n",
    "    \"slag\",\n",
    "    \"flyash\",\n",
    "    \"water\",\n",
    "    \"superplasticizer\",\n",
    "    \"coarseaggregate\",\n",
    "    \"fineaggregate\",\n",
    "    \"age\",\n",
    "]\n",
    "assembler = VectorAssembler(inputCols=features_list, outputCol=\"features\")\n",
    "test = assembler.transform(test).select(\"features\")\n",
    "\n",
    "# rescale each feature to range [min, max].\n",
    "scaled_test = scalerModel.transform(test)\n",
    "final_test = scaled_test.select(\"scaledFeatures\")\n",
    "final_test = final_test.withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "\n",
    "predictions = LR_BestModel.transform(final_test)\n",
    "response = predictions.select([\"prediction\"]).collect()\n",
    "response = response[0][0]\n",
    "print(\"Your predicted cement stregth is: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make recommendations of optimal values for cement ingredients (our features)\n",
    "\n",
    "See if you can find the optimal amount of cement to recommend holding the rest of the values from the previous question constant, assuming that the higher the cement strength value the better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n",
      "|summary|cement|csMPa|\n",
      "+-------+------+-----+\n",
      "|    min| 102.0| 2.33|\n",
      "|    max| 540.0| 82.6|\n",
      "+-------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First find out the min and max values for cement so we know what grid space to search\n",
    "df.select(\"cement\", \"csMPa\").summary(\"min\", \"max\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1542:=================================================>  (506 + 8) / 528]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|cement|       prediction|\n",
      "+------+-----------------+\n",
      "|   690|87.74969118909294|\n",
      "|   680|86.49330315692106|\n",
      "|   670|85.23691512474917|\n",
      "|   660|83.98052709257732|\n",
      "|   650| 82.7241390604054|\n",
      "+------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "values = [(540, 0.0, 0.0, 162, 2.5, 1040, 676, 28)]\n",
    "columns = [\n",
    "    \"cement\",\n",
    "    \"slag\",\n",
    "    \"flyash\",\n",
    "    \"water\",\n",
    "    \"superplasticizer\",\n",
    "    \"coarseaggregate\",\n",
    "    \"fineaggregate\",\n",
    "    \"age\",\n",
    "]\n",
    "test = spark.createDataFrame(values, columns)\n",
    "\n",
    "for value in range(50, 700, 10):\n",
    "    newRow = spark.createDataFrame(\n",
    "        [(value, 0.0, 0.0, 162, 2.5, 1040, 676, 28)], columns\n",
    "    )\n",
    "    test = test.union(newRow)\n",
    "\n",
    "# remember that we treated age for right skewness\n",
    "# so we need to convert the raw value to the transformed value\n",
    "test = test.withColumn(\"age\", log(\"age\") + 1)\n",
    "\n",
    "# Transform to a vector\n",
    "features_list = [\n",
    "    \"cement\",\n",
    "    \"slag\",\n",
    "    \"flyash\",\n",
    "    \"water\",\n",
    "    \"superplasticizer\",\n",
    "    \"coarseaggregate\",\n",
    "    \"fineaggregate\",\n",
    "    \"age\",\n",
    "]\n",
    "assembler = VectorAssembler(inputCols=features_list, outputCol=\"features\")\n",
    "# test = assembler.transform(test).select('features')\n",
    "test = assembler.transform(test)\n",
    "\n",
    "# rescale each feature to range [min, max].\n",
    "scaled_test = scalerModel.transform(test)\n",
    "final_test = scaled_test.withColumnRenamed(\"features\", \"oldfeatures\")\n",
    "final_test = final_test.withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "\n",
    "predictions = LR_BestModel.transform(final_test)\n",
    "predictions.select([\"cement\", \"prediction\"]).orderBy(\n",
    "    predictions[\"prediction\"].desc()\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='cement', ylabel='prediction'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions.select([\"cement\", \"prediction\"]).toPandas().plot.scatter(\n",
    "    x=\"cement\",\n",
    "    y=\"prediction\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
