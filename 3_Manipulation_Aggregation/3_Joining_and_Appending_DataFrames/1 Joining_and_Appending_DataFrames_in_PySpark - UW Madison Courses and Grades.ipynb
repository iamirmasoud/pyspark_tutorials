{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining and Appending DataFrames in PySpark\n",
    "\n",
    "In this lecture we will be reviewing the foundational concepts of joins and appending dataframes as well as the necessary PySpark calls to accomplish these tasks. Many of you may already be familiar with the common join types we will review here, so I also want to spend some time going through how to really conceptualize the joining process from a foundational level so you can effectively apply these concepts to a real usecase which we will also do here. Understanding these concepts early on will help you in your day to day job, and more importantly learning how to check your work and understand what you are doing help you to make less mistakes. \n",
    "\n",
    "So let's dig in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.7.139:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>joins</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7faca8811610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark  # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"joins\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate play data\n",
    "\n",
    "First some play data to help us grasp some concepts. Let's create a database that has two tables. \n",
    "\n",
    "**Key Terms**\n",
    " - **omnivore**: an animal which is able to consume both plants (like a herbivore) and meat (like a carnivore)\n",
    " - **herbivore**: any animal that eats only vegetation (i.e. that eats no meat)\n",
    " - **carnivore**: any animal that eats meat as the main part of its diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plant eaters (herbivores)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+-----------+\n",
      "|       name| id|eats_plants|\n",
      "+-----------+---+-----------+\n",
      "|      koala|  1|        yes|\n",
      "|caterpillar|  2|        yes|\n",
      "|       deer|  3|        yes|\n",
      "|      human|  4|        yes|\n",
      "+-----------+---+-----------+\n",
      "\n",
      "None\n",
      "Meat eaters (carnivores)\n",
      "+-----+---+---------+\n",
      "| name| id|eats_meat|\n",
      "+-----+---+---------+\n",
      "|shark|  5|      yes|\n",
      "| lion|  6|      yes|\n",
      "|tiger|  7|      yes|\n",
      "|human|  4|      yes|\n",
      "+-----+---+---------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "valuesP = [\n",
    "    (\"koala\", 1, \"yes\"),\n",
    "    (\"caterpillar\", 2, \"yes\"),\n",
    "    (\"deer\", 3, \"yes\"),\n",
    "    (\"human\", 4, \"yes\"),\n",
    "]\n",
    "eats_plants = spark.createDataFrame(valuesP, [\"name\", \"id\", \"eats_plants\"])\n",
    "\n",
    "valuesM = [\n",
    "    (\"shark\", 5, \"yes\"),\n",
    "    (\"lion\", 6, \"yes\"),\n",
    "    (\"tiger\", 7, \"yes\"),\n",
    "    (\"human\", 4, \"yes\"),\n",
    "]\n",
    "eats_meat = spark.createDataFrame(valuesM, [\"name\", \"id\", \"eats_meat\"])\n",
    "\n",
    "print(\"Plant eaters (herbivores)\")\n",
    "print(eats_plants.show())\n",
    "print(\"Meat eaters (carnivores)\")\n",
    "print(eats_meat.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appends\n",
    "\n",
    "Appending \"appends\" two dataframes together that have the exact same variables. You can think of it like stacking two or more blocks ON TOP of each other. To demonstrate this, we will simply join the same dataframe to itself since we don't really have a good use case for this. But hopefully this will help you imagine what to do. \n",
    "\n",
    "A common usecase would be joining the same table of information from one year to another year (i.e. 2012 + 2013 + ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('eats_plants df Counts:', 4, 3)\n",
      "('df_concat Counts:', 8, 3)\n",
      "+-----------+---+-----------+\n",
      "|       name| id|eats_plants|\n",
      "+-----------+---+-----------+\n",
      "|      koala|  1|        yes|\n",
      "|caterpillar|  2|        yes|\n",
      "|       deer|  3|        yes|\n",
      "|      human|  4|        yes|\n",
      "+-----------+---+-----------+\n",
      "\n",
      "None\n",
      "+-----------+---+-----------+\n",
      "|       name| id|eats_plants|\n",
      "+-----------+---+-----------+\n",
      "|      koala|  1|        yes|\n",
      "|caterpillar|  2|        yes|\n",
      "|       deer|  3|        yes|\n",
      "|      human|  4|        yes|\n",
      "|      koala|  1|        yes|\n",
      "|caterpillar|  2|        yes|\n",
      "|       deer|  3|        yes|\n",
      "|      human|  4|        yes|\n",
      "+-----------+---+-----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# So first replicate table and call it new_df\n",
    "new_df = eats_plants\n",
    "# Then append using the union function\n",
    "# this naming convention can be tricky to grasp for SQL enthusiasts\n",
    "# Where union just mean join\n",
    "df_concat = eats_plants.union(new_df)\n",
    "# We will test to see if this worked by getting before and after row counts\n",
    "print((\"eats_plants df Counts:\", eats_plants.count(), len(eats_plants.columns)))\n",
    "print((\"df_concat Counts:\", df_concat.count(), len(df_concat.columns)))\n",
    "print(eats_plants.show(5))\n",
    "print(df_concat.show(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Joins!\n",
    "\n",
    "Inner joins get us ONLY the values that appear in BOTH tables we are joining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Join Example\n",
      "+-----+---+-----------+---------+\n",
      "| name| id|eats_plants|eats_meat|\n",
      "+-----+---+-----------+---------+\n",
      "|human|  4|        yes|      yes|\n",
      "+-----+---+-----------+---------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inner_join = eats_plants.join(eats_meat, [\"name\", \"id\"], \"inner\")\n",
    "print(\"Inner Join Example\")\n",
    "print(inner_join.show())\n",
    "# So this is the only name that appears in BOTH dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Joins\n",
    "\n",
    "Left joins get us the values that appear in the left table and nothing additional from the right table except for its columns. A quick quality check we could do would be to make sure that the human column has the value \"yes\" for both eats_plants and eats_meat columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Join Example\n",
      "+-----------+---+-----------+---------+\n",
      "|       name| id|eats_plants|eats_meat|\n",
      "+-----------+---+-----------+---------+\n",
      "|      koala|  1|        yes|     null|\n",
      "|caterpillar|  2|        yes|     null|\n",
      "|       deer|  3|        yes|     null|\n",
      "|      human|  4|        yes|      yes|\n",
      "+-----------+---+-----------+---------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "left_join = eats_plants.join(\n",
    "    eats_meat, [\"name\", \"id\"], how=\"left\"\n",
    ")  # Could also use 'left_outer'\n",
    "print(\"Left Join Example\")\n",
    "print(left_join.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Joins\n",
    "\n",
    "Conditional joins have some additional logic that was not encompassed in the underlying join. For example, if we wanted to get all the values that appear in the left, **except** for those values that appear in BOTH tables, we could do this. Notice how human is left out now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional Left Join\n",
      "+-----------+---+-----------+---------+\n",
      "|       name| id|eats_plants|eats_meat|\n",
      "+-----------+---+-----------+---------+\n",
      "|      koala|  1|        yes|     null|\n",
      "|caterpillar|  2|        yes|     null|\n",
      "|       deer|  3|        yes|     null|\n",
      "+-----------+---+-----------+---------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conditional_join = eats_plants.join(eats_meat, [\"name\", \"id\"], how=\"left\").filter(\n",
    "    eats_meat.name.isNull()\n",
    ")\n",
    "print(\"Conditional Left Join\")\n",
    "print(conditional_join.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right Join\n",
    "\n",
    "A right join gets you the values that appear in the right table but not in the left. It also brings it's columns over of course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Join\n",
      "+-----+---+-----------+---------+\n",
      "| name| id|eats_plants|eats_meat|\n",
      "+-----+---+-----------+---------+\n",
      "|shark|  5|       null|      yes|\n",
      "| lion|  6|       null|      yes|\n",
      "|tiger|  7|       null|      yes|\n",
      "|human|  4|        yes|      yes|\n",
      "+-----+---+-----------+---------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "right_join = eats_plants.join(\n",
    "    eats_meat, [\"name\", \"id\"], how=\"right\"\n",
    ")  # Could also use 'right_outer'\n",
    "print(\"Right Join\")\n",
    "print(right_join.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Outer Joins\n",
    "\n",
    "Full outer joins will get all values from both tables, but notice that if there is a column that is common in both tables (ie. id and name in this case) that the join will take the value of the left table (see human id is p4 and not m4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Outer Join\n",
      "+-----------+---+-----------+---------+\n",
      "|       name| id|eats_plants|eats_meat|\n",
      "+-----------+---+-----------+---------+\n",
      "|caterpillar|  2|        yes|     null|\n",
      "|       deer|  3|        yes|     null|\n",
      "|      human|  4|        yes|      yes|\n",
      "|      koala|  1|        yes|     null|\n",
      "|       lion|  6|       null|      yes|\n",
      "|      shark|  5|       null|      yes|\n",
      "|      tiger|  7|       null|      yes|\n",
      "+-----------+---+-----------+---------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "full_outer_join = eats_plants.join(\n",
    "    eats_meat, [\"name\", \"id\"], how=\"full\"\n",
    ")  # Could also use 'full_outer'\n",
    "print(\"Full Outer Join\")\n",
    "print(full_outer_join.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alright now let's try with REAL data\n",
    "\n",
    "Thinking about how to join your data in real life will not be as easy as the above. You need to consider multiple aspects as you join tables in real life and ALWAYS conduct sanity checks to make sure you did it correctly. Let's look at an example below with real data.\n",
    "\n",
    "#### First, let's read in the datasets we will be working with\n",
    "\n",
    "Here is a neat function that will read in all the csv files from a directory (folder) in one shot and returns a separate dataframe for each dataset in the directory using the same naming convention. This is super useful if you have a large set of files and don't feel like writing a separate line for each dataset in the directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full list of dfs:\n",
      "['courses', 'course_offerings', 'grade_distributions', 'instructors', 'rooms', 'schedules', 'sections', 'subjects', 'subject_memberships', 'teachings']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"Datasets/uw-madison-courses/\"\n",
    "\n",
    "df_list = []\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filename_list = filename.split(\".\")  # separate path from .csv\n",
    "        df_name = filename_list[0]\n",
    "        df = spark.read.csv(path + filename, inferSchema=True, header=True)\n",
    "        df.name = df_name\n",
    "        df_list.append(df_name)\n",
    "        exec(df_name + \" = df\")\n",
    "\n",
    "# QA\n",
    "print(\"Full list of dfs:\")\n",
    "print(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this database\n",
    "\n",
    "You will notice that there are several tables in the uw-madision-courses folder that were read in above. This database will let you get a chance to practice your own custom joins and learn how the relationships between a real database work. Sometimes we don't know how they are related and we need to figure it out! I'll save that for the HW since we will be using the same database :) So I just wanted to introduce the database to you quickly here first. \n",
    "\n",
    "For this lecture, we will focus on the 4 datasets below and save the rest for the HW. Here is a look at some of the important variables we will be using to join our tables:\n",
    "\n",
    " - **course_offerings:** uuid, course_uuid, term_code, name\n",
    " - **instructors:** id, name\n",
    " - **sections:** uuid, course_offering_uuid,room_uuid, schedule_uuid\n",
    " - **teachings:** instructor_id, section_uuid\n",
    " \n",
    " **Source:** https://www.kaggle.com/Madgrades/uw-madison-courses\n",
    " \n",
    "Let's pretend that I am a student interested in seeing what courses are available. I suppose I would start by look at the course offerings table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>course_uuid</th>\n",
       "      <th>term_code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344b3ebe-da7e-314c-83ed-9425269695fd</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1092</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f718e6cd-33f0-3c14-a9a6-834d9c3610a8</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1082</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ea3b717c-d66b-30dc-8b37-964d9688295f</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1172</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>075da420-5f49-3dd0-93df-13e3c152e1b1</td>\n",
       "      <td>a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de</td>\n",
       "      <td>1114</td>\n",
       "      <td>Cooperative Education Prog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid                           course_uuid  \\\n",
       "0  344b3ebe-da7e-314c-83ed-9425269695fd  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de   \n",
       "1  f718e6cd-33f0-3c14-a9a6-834d9c3610a8  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de   \n",
       "2  ea3b717c-d66b-30dc-8b37-964d9688295f  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de   \n",
       "3  075da420-5f49-3dd0-93df-13e3c152e1b1  a3e3e1c3-543d-3bb5-ae65-5f2aec4ad1de   \n",
       "\n",
       "   term_code                        name  \n",
       "0       1092  Cooperative Education Prog  \n",
       "1       1082  Cooperative Education Prog  \n",
       "2       1172  Cooperative Education Prog  \n",
       "3       1114  Cooperative Education Prog  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the data\n",
    "course_offerings.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This course offers table is great, but I also want to know who teaches each course because I want to check the reviews of the instructor before I take the course. Let's see if we can join this table with the instructors table that contains the name of the instructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|id     |name              |\n",
      "+-------+------------------+\n",
      "|761703 |JOHN ARCHAMBAULT  |\n",
      "|3677061|STEPHANIE KANN    |\n",
      "|788586 |KATHY PREM        |\n",
      "|1600463|KRISTIN KLARKOWSKI|\n",
      "+-------+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instructors.show(4, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, so this table only contains 2 columns (id and name) and doesn't have the uuid or course uuid to join on. So we will need to see how we can accomplish the join we need. It looks like from the tables we have, we would need to take the following steps to get the variables we need. \n",
    "\n",
    " - **course_offerings (CO):** uuid, course_uuid, term_code, name\n",
    " - **instructors (I):** id, name\n",
    " - **sections (S):** uuid, course_offering_uuid,room_uuid, schedule_uuid\n",
    " - **teachings (T):** instructor_id, section_uuid\n",
    " \n",
    " I.id --> T.instructor_id\n",
    "                \\/\n",
    "          T.section_uuid --> S.uuid\n",
    "                              \\/\n",
    "                             S.course_offering_uuid --> CO.uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|instructor_id|        section_uuid|\n",
      "+-------------+--------------------+\n",
      "|       761703|45adf63c-48c9-365...|\n",
      "|       761703|c6280e23-5e43-385...|\n",
      "|       761703|9395dc21-15d1-3fa...|\n",
      "+-------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teachings.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instructor_id</th>\n",
       "      <th>name</th>\n",
       "      <th>section_uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761703</td>\n",
       "      <td>JOHN ARCHAMBAULT</td>\n",
       "      <td>45adf63c-48c9-3659-8561-07556d2d4ddf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>761703</td>\n",
       "      <td>JOHN ARCHAMBAULT</td>\n",
       "      <td>c6280e23-5e43-3859-893e-540d94993529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>761703</td>\n",
       "      <td>JOHN ARCHAMBAULT</td>\n",
       "      <td>9395dc21-15d1-3fab-8d1f-6f3fe6114c48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3677061</td>\n",
       "      <td>STEPHANIE KANN</td>\n",
       "      <td>b99e440b-39db-350a-81eb-b6eb1bd8b0bc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instructor_id              name                          section_uuid\n",
       "0         761703  JOHN ARCHAMBAULT  45adf63c-48c9-3659-8561-07556d2d4ddf\n",
       "1         761703  JOHN ARCHAMBAULT  c6280e23-5e43-3859-893e-540d94993529\n",
       "2         761703  JOHN ARCHAMBAULT  9395dc21-15d1-3fab-8d1f-6f3fe6114c48\n",
       "3        3677061    STEPHANIE KANN  b99e440b-39db-350a-81eb-b6eb1bd8b0bc"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to see all course offerings and who teaches it\n",
    "# Notice here that the variable we want to join on is different in the two datasets.\n",
    "# PySpark makes it easy to account for that\n",
    "step1 = teachings.join(\n",
    "    instructors, teachings.instructor_id == instructors.id, how=\"left\"\n",
    ").select([\"instructor_id\", \"name\", \"section_uuid\"])\n",
    "step1.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>course_offering_uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JAMES STEELE</td>\n",
       "      <td>dfac15fb-e446-339e-9403-38b270895b6c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TERESA CLARK</td>\n",
       "      <td>878d4f26-4e7e-3cec-b2e3-28fd56d6489c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JAMES STEELE</td>\n",
       "      <td>3fc6bfe1-7929-3f2e-af13-5185f1cf7383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STEPHANIE KANN</td>\n",
       "      <td>ea3b717c-d66b-30dc-8b37-964d9688295f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                  course_offering_uuid\n",
       "0    JAMES STEELE  dfac15fb-e446-339e-9403-38b270895b6c\n",
       "1    TERESA CLARK  878d4f26-4e7e-3cec-b2e3-28fd56d6489c\n",
       "2    JAMES STEELE  3fc6bfe1-7929-3f2e-af13-5185f1cf7383\n",
       "3  STEPHANIE KANN  ea3b717c-d66b-30dc-8b37-964d9688295f"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step2 = step1.join(sections, step1.section_uuid == sections.uuid, how=\"left\").select(\n",
    "    [\"name\", \"course_offering_uuid\"]\n",
    ")\n",
    "step2.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instructor</th>\n",
       "      <th>name</th>\n",
       "      <th>course_offering_uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MICHAEL CONNORS</td>\n",
       "      <td>Special Topics</td>\n",
       "      <td>128f24cf-b7bf-3a8b-8f04-136c7b6fa556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RICK JENISON</td>\n",
       "      <td>Research</td>\n",
       "      <td>f513b3a7-9fdc-30f2-9f50-666870298ead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUSANNE BARNETT</td>\n",
       "      <td>Advanced Independent Study</td>\n",
       "      <td>9dcee3f1-0909-318b-8a3d-72c931959656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THOMAS JAHNS</td>\n",
       "      <td>Master's Research or Thesis</td>\n",
       "      <td>f850ab24-740c-311a-a669-804a3fea7b0b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        instructor                         name  \\\n",
       "0  MICHAEL CONNORS               Special Topics   \n",
       "1     RICK JENISON                     Research   \n",
       "2  SUSANNE BARNETT   Advanced Independent Study   \n",
       "3     THOMAS JAHNS  Master's Research or Thesis   \n",
       "\n",
       "                   course_offering_uuid  \n",
       "0  128f24cf-b7bf-3a8b-8f04-136c7b6fa556  \n",
       "1  f513b3a7-9fdc-30f2-9f50-666870298ead  \n",
       "2  9dcee3f1-0909-318b-8a3d-72c931959656  \n",
       "3  f850ab24-740c-311a-a669-804a3fea7b0b  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step3 = (\n",
    "    step2.withColumnRenamed(\"name\", \"instructor\")\n",
    "    .join(\n",
    "        course_offerings,\n",
    "        step2.course_offering_uuid == course_offerings.uuid,\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .select([\"instructor\", \"name\", \"course_offering_uuid\"])\n",
    ")\n",
    "step3.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! Sometimes it's helpful to think through joins step by step like this. I hope that helped get the concept down. \n",
    "\n",
    "## One final really cool way to join datasets: The Levenshtien distance!\n",
    "\n",
    "Which basically counts the number of edits you would need to make to make too strings equal to eachother. I'll let you figure the joining part in the HW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+---------+-------+\n",
      "|Input|Option1|  Option2|Option3|\n",
      "+-----+-------+---------+-------+\n",
      "| Aple|  Apple|Microsoft|    IBM|\n",
      "+-----+-------+---------+-------+\n",
      "\n",
      "Correct this company name: Aple\n",
      "+-----+\n",
      "|Apple|\n",
      "+-----+\n",
      "|    1|\n",
      "+-----+\n",
      "\n",
      "+---------+\n",
      "|Microsoft|\n",
      "+---------+\n",
      "|        9|\n",
      "+---------+\n",
      "\n",
      "+---+\n",
      "|IBM|\n",
      "+---+\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the levenshtein distance beween two strings\n",
    "# pyspark.sql.functions.levenshtein(left, right)\n",
    "\n",
    "from pyspark.sql.functions import levenshtein\n",
    "\n",
    "df0 = spark.createDataFrame(\n",
    "    [(\"Aple\", \"Apple\", \"Microsoft\", \"IBM\")], [\"Input\", \"Option1\", \"Option2\", \"Option3\"]\n",
    ")\n",
    "df0.show()\n",
    "print(\"Correct this company name: Aple\")\n",
    "df0.select(levenshtein(\"Input\", \"Option1\").alias(\"Apple\")).show()\n",
    "df0.select(levenshtein(\"Input\", \"Option2\").alias(\"Microsoft\")).show()\n",
    "df0.select(levenshtein(\"Input\", \"Option3\").alias(\"IBM\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great job! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
